[core]
no_lock = True
log_level = WARNING

[worker]
keep_alive = False
ping_interval = 20
wait_interval = 20
max_reschedules = 10

[DEFAULT]
name = KingMaker
ENV_NAME = KingMakerF

; storing the output locally (local) or on grid (wlcg)
; when using local, make sure to ajust the htcondor requirements so all local paths are accessible
; for ETP, that is TARGET.ProvidesEtpResources
output_destination = grid

; if the local path is set, the output will be copied to the local path after the job is finished
local_output_path = /ceph/${USER}/CROWN/ntuples/
; grid storage protocol and path usable from submitting machine and worker nodes of cluster
; job in- and output will be stored in $wlcg_path under subdirectory of analysis $name
wlcg_path = root://cmsdcache-kit-disk.gridka.de//store/user/${USER}/CROWN/ntuples/
; default htcondor job submission configuration (modifiable for each task)
htcondor_accounting_group = cms.higgs
htcondor_remote_job = True
htcondor_request_cpus = 4
# htcondor_request_gpus = 1
; for all cores in total
htcondor_universe = docker
; create log files in htcondor jobs
transfer_logs = True
; set local scheduler
local_scheduler = False
scheduler_port = ${LUIGIPORT}
; set tolerance for workflow success with failed branches
tolerance = 0.00
acceptance = 1.00
; submit only missing htcondor workflow branches (should always be true)
only_missing = True

; bootstrap file to be sourced at beginning of htcondor jobs (relative PATH to framework.py)
bootstrap_file = setup_law_remote.sh
files_per_task = 10
; scopes and shifts are to be provided in the config, or as command line arguments via --scope and --shift
; in both cases, the values are expected to be comma-separated lists without spaces or quotes
scopes = mt,et
shifts = None

[CROWNBuild]
build_dir = build
install_dir = tarballs

[CROWNBuildFriend]
build_dir = build
install_dir = tarballs

[CROWNBuildMultiFriend]
build_dir = build
install_dir = tarballs

[BuildCROWNLib]
build_dir = build
install_dir = tarballs

[CROWNRun]
; HTCondor
htcondor_walltime = 10800
htcondor_request_memory = 16000
htcondor_requirements = TARGET.ProvidesCPU && TARGET.ProvidesIO
htcondor_request_disk = 20000000
# for these eras, only one file per task is processed
problematic_eras = ["2018B", "2017C", "2016B-ver2"]

[CROWNFriends]
; HTCondor
htcondor_walltime = 10800
htcondor_request_memory = 16000
htcondor_requirements = TARGET.ProvidesCPU && TARGET.ProvidesIO
htcondor_request_disk = 20000000
# friends have to be run in single core mode to ensure a correct order of the tree entries
htcondor_request_cpus = 1

[CROWNMultiFriends]
; HTCondor
htcondor_walltime = 10800
htcondor_request_memory = 16000
htcondor_requirements = TARGET.ProvidesCPU && TARGET.ProvidesIO
htcondor_request_disk = 20000000
# friends have to be run in single core mode to ensure a correct order of the tree entries
htcondor_request_cpus = 1

[ProduceFriends]
dataset_database = sample_database/datasets.json

[ProduceMultiFriends]
dataset_database = sample_database/datasets.json
# the mapping is "config_name": "friend_name"
friend_mapping = {}
# friend_mapping = {
#     "unittest_friends": "id_iso_weights",
#     "unittest_friends_2": "svfit"}

[ProduceSamples]
dataset_database = sample_database/datasets.json

[ConfigureDatasets]
silent = True
# set to False to print out the datasets
